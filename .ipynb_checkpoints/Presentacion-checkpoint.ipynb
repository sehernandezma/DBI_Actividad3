{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ex_5D716TyfB"
   },
   "source": [
    "## Actividad 03: Regresión\n",
    "### Sebastián Hernández Mantilla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SGHAMvtQUGSj"
   },
   "source": [
    "## Predicción del precio de la vivienda en Taiwan\n",
    "####  El ejercicio de predicción fue desarrollado en python con ayuda de las librerías de Sickit Learn y Keras. La medida de error usada fue el error cuadratico medio (MSE).\n",
    "#### El impacto de las variables para cada modelo se obtuvo de ScikitLearn y para la visualización de esto se tomó el valor absoluto. En primer lugar se hace un breve análisis visual de los datos y luego se presenta, para cada modelo, el código usado, el resultado del error y una gráfica con el impacto de las variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249
    },
    "id": "jkgFvaPOWddb",
    "outputId": "dc9f0966-b713-4a76-c789-9901fd0c6db6",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1 transaction date</th>\n",
       "      <th>X2 house age</th>\n",
       "      <th>X3 distance to the nearest MRT station</th>\n",
       "      <th>X4 number of convenience stores</th>\n",
       "      <th>X5 latitude</th>\n",
       "      <th>X6 longitude</th>\n",
       "      <th>Y house price of unit area</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012.916667</td>\n",
       "      <td>32.0</td>\n",
       "      <td>84.87882</td>\n",
       "      <td>10</td>\n",
       "      <td>24.98298</td>\n",
       "      <td>121.54024</td>\n",
       "      <td>37.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012.916667</td>\n",
       "      <td>19.5</td>\n",
       "      <td>306.59470</td>\n",
       "      <td>9</td>\n",
       "      <td>24.98034</td>\n",
       "      <td>121.53951</td>\n",
       "      <td>42.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013.583333</td>\n",
       "      <td>13.3</td>\n",
       "      <td>561.98450</td>\n",
       "      <td>5</td>\n",
       "      <td>24.98746</td>\n",
       "      <td>121.54391</td>\n",
       "      <td>47.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013.500000</td>\n",
       "      <td>13.3</td>\n",
       "      <td>561.98450</td>\n",
       "      <td>5</td>\n",
       "      <td>24.98746</td>\n",
       "      <td>121.54391</td>\n",
       "      <td>54.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012.833333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>390.56840</td>\n",
       "      <td>5</td>\n",
       "      <td>24.97937</td>\n",
       "      <td>121.54245</td>\n",
       "      <td>43.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    X1 transaction date  X2 house age  X3 distance to the nearest MRT station  \\\n",
       "No                                                                              \n",
       "1           2012.916667          32.0                                84.87882   \n",
       "2           2012.916667          19.5                               306.59470   \n",
       "3           2013.583333          13.3                               561.98450   \n",
       "4           2013.500000          13.3                               561.98450   \n",
       "5           2012.833333           5.0                               390.56840   \n",
       "\n",
       "    X4 number of convenience stores  X5 latitude  X6 longitude  \\\n",
       "No                                                               \n",
       "1                                10     24.98298     121.54024   \n",
       "2                                 9     24.98034     121.53951   \n",
       "3                                 5     24.98746     121.54391   \n",
       "4                                 5     24.98746     121.54391   \n",
       "5                                 5     24.97937     121.54245   \n",
       "\n",
       "    Y house price of unit area  \n",
       "No                              \n",
       "1                         37.9  \n",
       "2                         42.2  \n",
       "3                         47.3  \n",
       "4                         54.8  \n",
       "5                         43.1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "df = pd.read_excel('Real estate valuation data set.xlsx',index_col='No')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imagenes\\graficaRelacion.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Y, (Precio/U de area):\n",
    "- Se observa que a mayor número de tiendas cercanas el precio tiende a crecer ligeramente\n",
    "- La distancia a la estación de transporte masivo mas cercana y el precio muestra una relación inversa donde las casas con mayor precio estan mas cerca a una estación.                                                                                  \n",
    "- Para la longitud y latitud el precio crece a mayor sean los valores de las 2 variables\n",
    "\n",
    "### Relación entre variables predictivas:\n",
    "\n",
    "- Se observa que la variable X3, (distancia a la estación de transporte masivo más cercano), tiende a valores muy bajos para ciertos valores de X5 y X6, (longitud y latitud), de esto se infiere que la mayor cantidad de estaciones están centradas en una ubicación especifica.\n",
    "- Hay mayor cantidad de tiendas alrededor de las casas más cercanas a una estación de transporte masivo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df_=df.rename(columns={\"X1 transaction date\":\"X1\",'X2 house age':'X2','X3 distance to the nearest MRT station':'X3',\n",
    "                       'X4 number of convenience stores':'X4','X5 latitude':'X5','X6 longitude':'X6',\n",
    "                       'Y house price of unit area':'Y'})\n",
    "corrMatrix = df_.corr()\n",
    "sns.heatmap(corrMatrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imagenes\\correlacion.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De la matriz de correlación:\n",
    "- X3 tiene los valores más altos de correlación con las variables predictivas X4,X5,X6 y la variable Y a predecir.\n",
    "- X1 tiene los valores más bajos con el resto de variables, por lo que no se tendrá en cuenta para el entrenamiento de los modelos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descripción del data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X2 house age</th>\n",
       "      <th>X3 distance to the nearest MRT station</th>\n",
       "      <th>X4 number of convenience stores</th>\n",
       "      <th>X5 latitude</th>\n",
       "      <th>X6 longitude</th>\n",
       "      <th>Y house price of unit area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>414.000000</td>\n",
       "      <td>414.000000</td>\n",
       "      <td>414.000000</td>\n",
       "      <td>414.000000</td>\n",
       "      <td>414.000000</td>\n",
       "      <td>414.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17.712560</td>\n",
       "      <td>1083.885689</td>\n",
       "      <td>4.094203</td>\n",
       "      <td>24.969030</td>\n",
       "      <td>121.533361</td>\n",
       "      <td>37.980193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.392485</td>\n",
       "      <td>1262.109595</td>\n",
       "      <td>2.945562</td>\n",
       "      <td>0.012410</td>\n",
       "      <td>0.015347</td>\n",
       "      <td>13.606488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.382840</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.932070</td>\n",
       "      <td>121.473530</td>\n",
       "      <td>7.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.025000</td>\n",
       "      <td>289.324800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.963000</td>\n",
       "      <td>121.528085</td>\n",
       "      <td>27.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>16.100000</td>\n",
       "      <td>492.231300</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>24.971100</td>\n",
       "      <td>121.538630</td>\n",
       "      <td>38.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>28.150000</td>\n",
       "      <td>1454.279000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>24.977455</td>\n",
       "      <td>121.543305</td>\n",
       "      <td>46.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>43.800000</td>\n",
       "      <td>6488.021000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>25.014590</td>\n",
       "      <td>121.566270</td>\n",
       "      <td>117.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       X2 house age  X3 distance to the nearest MRT station  \\\n",
       "count    414.000000                              414.000000   \n",
       "mean      17.712560                             1083.885689   \n",
       "std       11.392485                             1262.109595   \n",
       "min        0.000000                               23.382840   \n",
       "25%        9.025000                              289.324800   \n",
       "50%       16.100000                              492.231300   \n",
       "75%       28.150000                             1454.279000   \n",
       "max       43.800000                             6488.021000   \n",
       "\n",
       "       X4 number of convenience stores  X5 latitude  X6 longitude  \\\n",
       "count                       414.000000   414.000000    414.000000   \n",
       "mean                          4.094203    24.969030    121.533361   \n",
       "std                           2.945562     0.012410      0.015347   \n",
       "min                           0.000000    24.932070    121.473530   \n",
       "25%                           1.000000    24.963000    121.528085   \n",
       "50%                           4.000000    24.971100    121.538630   \n",
       "75%                           6.000000    24.977455    121.543305   \n",
       "max                          10.000000    25.014590    121.566270   \n",
       "\n",
       "       Y house price of unit area  \n",
       "count                  414.000000  \n",
       "mean                    37.980193  \n",
       "std                     13.606488  \n",
       "min                      7.600000  \n",
       "25%                     27.700000  \n",
       "50%                     38.450000  \n",
       "75%                     46.600000  \n",
       "max                    117.500000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['X1 transaction date'],axis=1,inplace=True)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación de la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se inicializa la herramienta para escalar los datos\n",
    "X = df.drop(['Y house price of unit area'],axis=1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Todas las variables\n",
    "scaled_x = scaler.fit_transform(X)\n",
    "# Se dividen los datos en 80-20 para el set de entrenamiento y de testeo\n",
    "X_train1,X_test1,y_train1,y_test1 = train_test_split(scaled_x,df['Y house price of unit area'],test_size = 0.2, random_state=42)\n",
    "\n",
    "################################################################################################################################\n",
    "\n",
    "X1 = X.drop(['X5 latitude','X6 longitude'],axis=1)\n",
    "scaled_x = scaler.fit_transform(X1)\n",
    "X_train,X_test,y_train,y_test = train_test_split(scaled_x,df['Y house price of unit area'],test_size = 0.2, random_state=42)\n",
    "\n",
    "X_train2,X_test2,y_train2,y_test2 = train_test_split(df.iloc[:, 3:5],df['Y house price of unit area'],\n",
    "                                                 test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión lineal clásica\n",
    "##### Para ver como afecta el uso de las variables X5 y X6, solo en regresión clásica, se quiere usar un modelo con todas las variables , otro solo con latitud y longitud y otro con todas las variables menos latitud y longitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error MSE: \n",
      "54.58094520086212\n"
     ]
    }
   ],
   "source": [
    "reg3 = LinearRegression().fit(X_train1,y_train1)\n",
    "y_pred = reg.predict(X_test1)\n",
    "\n",
    "print('Error MSE: ')\n",
    "print(mean_squared_error(y_test1, y_pred))\n",
    "reg_coef = reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(8, 3))\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "variables = X.columns\n",
    "importancia = np.absolute(reg3.coef_)\n",
    "ax.barh(variables,importancia)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imagenes\\regrelinealclasica.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KcB6juosUxAq",
    "outputId": "10ff02ea-7f82-4a4e-9cad-e75d2d214f9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error MSE: \n",
      "58.88825128983576\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "reg = LinearRegression().fit(X_train,y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "print('Error MSE: ')\n",
    "print(mean_squared_error(y_test, y_pred))\n",
    "reg_coef = reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(8, 3))\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "variables = X1.columns\n",
    "importancia = np.absolute(reg.coef_)\n",
    "ax.barh(variables,importancia)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imagenes\\regclasica2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error MSE: \n",
      "82.08014010115268\n"
     ]
    }
   ],
   "source": [
    "reg2 = LinearRegression().fit(X_train2,y_train2)\n",
    "y_pred = reg2.predict(X_test2)\n",
    "\n",
    "print('Error MSE: ')\n",
    "print(mean_squared_error(y_test2, y_pred))\n",
    "reg_coef = reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8o7VzMuXXWqJ"
   },
   "source": [
    "### Regresión lineal Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z53XBO20X0nd",
    "outputId": "51d2558e-9b18-4250-cc8f-a25b1c6401ab",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error MSE: \n",
      "61.35399330573307\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "reg_elast = ElasticNet()\n",
    "reg_elast.fit(X_train1,y_train1)\n",
    "y_pred = reg_elast.predict(X_test1)\n",
    "print('Error MSE: ')\n",
    "print(mean_squared_error(y_test, y_pred))\n",
    "reg_elast_coef = reg_elast.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "variables = df.columns[0:-1]\n",
    "importancia = np.absolute(reg_elast.coef_)\n",
    "ax.barh(variables,importancia)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imagenes\\regreElastic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvRXen2lFx_g"
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24628009 0.69727733 0.05644258]\n"
     ]
    }
   ],
   "source": [
    "print(importancia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debido a que los arboles no son afectados por la escala de los datos, en este caso, se usan todas las variables\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,df['Y house price of unit area'],test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3TkkE4IvHvXv",
    "outputId": "2be920ff-397c-4067-f80c-837ceef35599"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error MSE: \n",
      "36.28159186986518\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "random_forest = RandomForestRegressor()\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "print('Error MSE: ')\n",
    "print(mean_squared_error(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "variables = X.columns\n",
    "importancia = np.absolute(random_forest.feature_importances_)\n",
    "ax.barh(variables,importancia)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imagenes\\randomforest.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NawVWt6DYD0N"
   },
   "source": [
    "### XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4lnFqOwEYGBi",
    "outputId": "e5e56142-955f-4c72-987e-1a4688756f62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error MSE: \n",
      "39.8139344587423\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "#xg = XGBRegressor(n_estimators=100, max_depth=10, eta=0.1, subsample=0.7, colsample_bytree=0.8)\n",
    "xg = XGBRegressor()\n",
    "\n",
    "xg.fit(X_train, y_train)\n",
    "y_pred = xg.predict(X_test)\n",
    "\n",
    "print('Error MSE: ')\n",
    "print(mean_squared_error(y_test, y_pred))\n",
    "xg_coef = xg.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k6d_jP-ggN1M",
    "outputId": "bb15f252-88ea-4899-e335-6f231a82a2c6",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0463699 , 0.664023  , 0.06194649, 0.12445176, 0.1032089 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "variables = df.columns[0:-1]\n",
    "importancia = np.absolute(xg.feature_importances_)\n",
    "ax.barh(variables,importancia)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imagenes\\xgBoost.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6nL6HTbYuFd"
   },
   "source": [
    "### Support Vectors Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "1z_yql-IXYB-"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_y = df['Y house price of unit area']\n",
    "scaled_x = scaler.fit_transform(df.drop(columns=['Y house price of unit area'],axis=1))\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(scaled_x,scaled_y,test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qqMAMM4aYRKF",
    "outputId": "33e5206c-fab0-44e1-bb98-4899471124cb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error MSE: \n",
      "60.725841689226584\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "svm = SVR(kernel='linear')\n",
    "svm.fit(X_train1,y_train1)\n",
    "y_pred = svm.predict(X_test1)\n",
    "print('Error MSE: ')\n",
    "print(mean_squared_error(y_test1, y_pred))\n",
    "#svm.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "variables = X.columns\n",
    "importancia = np.absolute(svm.coef_[0])\n",
    "ax.barh(variables,importancia)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imagenes\\SVM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PwBUmQJjY3N_"
   },
   "source": [
    "### Red Neuronal\n",
    "#### Se usó el MSE y el MAE como funciones de pérdida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yVUjHYTwY5A5",
    "outputId": "ee09e699-a411-4d46-9234-41ffdfb10cdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "6/6 [==============================] - 1s 148ms/step - loss: 1212.7402 - mse: 1212.7402 - mae: 30.3724 - val_loss: 1508.1959 - val_mse: 1508.1959 - val_mae: 33.4689\n",
      "Epoch 2/75\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1156.5328 - mse: 1156.5327 - mae: 29.8880 - val_loss: 1448.9918 - val_mse: 1448.9917 - val_mae: 32.6836\n",
      "Epoch 3/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1088.1287 - mse: 1088.1287 - mae: 28.7321 - val_loss: 1385.5951 - val_mse: 1385.5951 - val_mae: 31.8925\n",
      "Epoch 4/75\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1030.1753 - mse: 1030.1753 - mae: 27.7805 - val_loss: 1318.3425 - val_mse: 1318.3424 - val_mae: 30.9418\n",
      "Epoch 5/75\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 967.2819 - mse: 967.2819 - mae: 26.8653 - val_loss: 1257.0819 - val_mse: 1257.0819 - val_mae: 30.0582\n",
      "Epoch 6/75\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 912.9451 - mse: 912.9451 - mae: 26.0239 - val_loss: 1196.6714 - val_mse: 1196.6714 - val_mae: 29.2425\n",
      "Epoch 7/75\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 861.3686 - mse: 861.3686 - mae: 25.0831 - val_loss: 1140.1206 - val_mse: 1140.1206 - val_mae: 28.4989\n",
      "Epoch 8/75\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 804.3870 - mse: 804.3870 - mae: 24.1502 - val_loss: 1073.4906 - val_mse: 1073.4906 - val_mae: 27.3333\n",
      "Epoch 9/75\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 745.1896 - mse: 745.1896 - mae: 23.1150 - val_loss: 1004.1925 - val_mse: 1004.1925 - val_mae: 26.3241\n",
      "Epoch 10/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 683.8279 - mse: 683.8279 - mae: 21.9718 - val_loss: 933.9156 - val_mse: 933.9157 - val_mae: 25.3008\n",
      "Epoch 11/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 624.5649 - mse: 624.5649 - mae: 20.8687 - val_loss: 860.8370 - val_mse: 860.8370 - val_mae: 24.1244\n",
      "Epoch 12/75\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 557.9302 - mse: 557.9302 - mae: 19.4996 - val_loss: 785.3895 - val_mse: 785.3895 - val_mae: 22.4912\n",
      "Epoch 13/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 511.1060 - mse: 511.1060 - mae: 18.4252 - val_loss: 714.1479 - val_mse: 714.1479 - val_mae: 21.1519\n",
      "Epoch 14/75\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 452.7346 - mse: 452.7346 - mae: 17.2093 - val_loss: 652.6400 - val_mse: 652.6400 - val_mae: 20.4823\n",
      "Epoch 15/75\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 396.1524 - mse: 396.1524 - mae: 15.7465 - val_loss: 599.9890 - val_mse: 599.9890 - val_mae: 18.7513\n",
      "Epoch 16/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 339.1245 - mse: 339.1245 - mae: 14.2348 - val_loss: 505.2301 - val_mse: 505.2301 - val_mae: 17.3552\n",
      "Epoch 17/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 287.6193 - mse: 287.6193 - mae: 13.2720 - val_loss: 432.3472 - val_mse: 432.3472 - val_mae: 14.9051\n",
      "Epoch 18/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 238.8875 - mse: 238.8875 - mae: 11.4377 - val_loss: 372.6318 - val_mse: 372.6318 - val_mae: 13.3508\n",
      "Epoch 19/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 199.4809 - mse: 199.4809 - mae: 10.6895 - val_loss: 323.3661 - val_mse: 323.3661 - val_mae: 12.4982\n",
      "Epoch 20/75\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 167.6119 - mse: 167.6119 - mae: 9.6848 - val_loss: 288.8970 - val_mse: 288.8970 - val_mae: 11.0588\n",
      "Epoch 21/75\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 152.3924 - mse: 152.3924 - mae: 9.0761 - val_loss: 259.4858 - val_mse: 259.4858 - val_mae: 10.3438\n",
      "Epoch 22/75\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 139.8603 - mse: 139.8603 - mae: 8.8187 - val_loss: 243.4812 - val_mse: 243.4812 - val_mae: 9.7622\n",
      "Epoch 23/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 128.1980 - mse: 128.1980 - mae: 8.4389 - val_loss: 229.9206 - val_mse: 229.9206 - val_mae: 9.5462\n",
      "Epoch 24/75\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 120.1926 - mse: 120.1926 - mae: 8.2730 - val_loss: 220.9747 - val_mse: 220.9747 - val_mae: 9.0796\n",
      "Epoch 25/75\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 115.6447 - mse: 115.6447 - mae: 8.0475 - val_loss: 209.6136 - val_mse: 209.6136 - val_mae: 8.9749\n",
      "Epoch 26/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 109.5338 - mse: 109.5338 - mae: 8.0707 - val_loss: 199.7238 - val_mse: 199.7238 - val_mae: 8.6979\n",
      "Epoch 27/75\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 105.1437 - mse: 105.1437 - mae: 7.8212 - val_loss: 192.1225 - val_mse: 192.1225 - val_mae: 8.4734\n",
      "Epoch 28/75\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 103.0124 - mse: 103.0124 - mae: 7.8702 - val_loss: 186.8308 - val_mse: 186.8308 - val_mae: 8.3661\n",
      "Epoch 29/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 99.0677 - mse: 99.0677 - mae: 7.6386 - val_loss: 183.1266 - val_mse: 183.1266 - val_mae: 8.2957\n",
      "Epoch 30/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 95.9980 - mse: 95.9980 - mae: 7.5307 - val_loss: 180.3674 - val_mse: 180.3674 - val_mae: 8.3912\n",
      "Epoch 31/75\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 96.1197 - mse: 96.1197 - mae: 7.6992 - val_loss: 177.7075 - val_mse: 177.7075 - val_mae: 8.1528\n",
      "Epoch 32/75\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 92.7237 - mse: 92.7237 - mae: 7.3846 - val_loss: 174.8457 - val_mse: 174.8457 - val_mae: 8.0994\n",
      "Epoch 33/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 91.0746 - mse: 91.0746 - mae: 7.3354 - val_loss: 173.1532 - val_mse: 173.1532 - val_mae: 8.0826\n",
      "Epoch 34/75\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 89.3025 - mse: 89.3025 - mae: 7.2392 - val_loss: 170.4680 - val_mse: 170.4680 - val_mae: 7.9745\n",
      "Epoch 35/75\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 88.0378 - mse: 88.0378 - mae: 7.1602 - val_loss: 168.5618 - val_mse: 168.5618 - val_mae: 8.1053\n",
      "Epoch 36/75\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 88.7968 - mse: 88.7968 - mae: 7.3800 - val_loss: 168.9274 - val_mse: 168.9274 - val_mae: 7.9343\n",
      "Epoch 37/75\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 87.6458 - mse: 87.6458 - mae: 7.1339 - val_loss: 165.9505 - val_mse: 165.9505 - val_mae: 7.9599\n",
      "Epoch 38/75\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 86.2968 - mse: 86.2968 - mae: 7.2276 - val_loss: 164.7000 - val_mse: 164.7000 - val_mae: 7.8123\n",
      "Epoch 39/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 83.2896 - mse: 83.2896 - mae: 6.9685 - val_loss: 163.4578 - val_mse: 163.4578 - val_mae: 7.7986\n",
      "Epoch 40/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 82.1016 - mse: 82.1016 - mae: 6.8947 - val_loss: 162.4143 - val_mse: 162.4143 - val_mae: 7.8079\n",
      "Epoch 41/75\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 81.1080 - mse: 81.1080 - mae: 6.9230 - val_loss: 161.2779 - val_mse: 161.2779 - val_mae: 7.7309\n",
      "Epoch 42/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 82.1855 - mse: 82.1855 - mae: 6.9478 - val_loss: 160.0356 - val_mse: 160.0356 - val_mae: 7.7496\n",
      "Epoch 43/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 78.9993 - mse: 78.9993 - mae: 6.7508 - val_loss: 161.2702 - val_mse: 161.2702 - val_mae: 7.8497\n",
      "Epoch 44/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 79.0845 - mse: 79.0845 - mae: 6.7707 - val_loss: 161.4147 - val_mse: 161.4147 - val_mae: 7.7440\n",
      "Epoch 45/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 78.1878 - mse: 78.1878 - mae: 6.6334 - val_loss: 158.7108 - val_mse: 158.7108 - val_mae: 7.7743\n",
      "Epoch 46/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 77.8328 - mse: 77.8328 - mae: 6.8242 - val_loss: 157.0415 - val_mse: 157.0415 - val_mae: 7.6541\n",
      "Epoch 47/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 78.1141 - mse: 78.1141 - mae: 6.7235 - val_loss: 155.5665 - val_mse: 155.5665 - val_mae: 7.7219\n",
      "Epoch 48/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 77.5874 - mse: 77.5874 - mae: 6.7993 - val_loss: 154.8470 - val_mse: 154.8470 - val_mae: 7.5927\n",
      "Epoch 49/75\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 77.5250 - mse: 77.5250 - mae: 6.7166 - val_loss: 153.3896 - val_mse: 153.3896 - val_mae: 7.6103\n",
      "Epoch 50/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 74.2661 - mse: 74.2661 - mae: 6.5168 - val_loss: 156.1951 - val_mse: 156.1951 - val_mae: 7.5617\n",
      "Epoch 51/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 73.7535 - mse: 73.7535 - mae: 6.4062 - val_loss: 154.2850 - val_mse: 154.2850 - val_mae: 7.5910\n",
      "Epoch 52/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 72.4371 - mse: 72.4371 - mae: 6.3942 - val_loss: 152.9173 - val_mse: 152.9173 - val_mae: 7.5059\n",
      "Epoch 53/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 73.0068 - mse: 73.0068 - mae: 6.4795 - val_loss: 152.8561 - val_mse: 152.8561 - val_mae: 7.4724\n",
      "Epoch 54/75\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 72.2864 - mse: 72.2864 - mae: 6.3589 - val_loss: 151.9648 - val_mse: 151.9648 - val_mae: 7.6463\n",
      "Epoch 55/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 71.8967 - mse: 71.8967 - mae: 6.4284 - val_loss: 152.4530 - val_mse: 152.4530 - val_mae: 7.4281\n",
      "Epoch 56/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 71.3249 - mse: 71.3249 - mae: 6.2631 - val_loss: 151.7546 - val_mse: 151.7546 - val_mae: 7.4711\n",
      "Epoch 57/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 70.8216 - mse: 70.8216 - mae: 6.2683 - val_loss: 150.8410 - val_mse: 150.8410 - val_mae: 7.4227\n",
      "Epoch 58/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 70.3462 - mse: 70.3462 - mae: 6.2673 - val_loss: 149.8798 - val_mse: 149.8798 - val_mae: 7.6622\n",
      "Epoch 59/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 74.6380 - mse: 74.6380 - mae: 6.6826 - val_loss: 150.7230 - val_mse: 150.7230 - val_mae: 7.3515\n",
      "Epoch 60/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 72.1362 - mse: 72.1362 - mae: 6.3175 - val_loss: 147.8234 - val_mse: 147.8234 - val_mae: 7.5338\n",
      "Epoch 61/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 69.9010 - mse: 69.9010 - mae: 6.3147 - val_loss: 147.8737 - val_mse: 147.8737 - val_mae: 7.2461\n",
      "Epoch 62/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 69.3424 - mse: 69.3424 - mae: 6.1699 - val_loss: 148.0349 - val_mse: 148.0349 - val_mae: 7.2277\n",
      "Epoch 63/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 70.5425 - mse: 70.5425 - mae: 6.1615 - val_loss: 146.9137 - val_mse: 146.9137 - val_mae: 7.3851\n",
      "Epoch 64/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 71.0949 - mse: 71.0949 - mae: 6.4059 - val_loss: 147.3223 - val_mse: 147.3223 - val_mae: 7.1706\n",
      "Epoch 65/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 70.1304 - mse: 70.1304 - mae: 6.1219 - val_loss: 146.1427 - val_mse: 146.1427 - val_mae: 7.5245\n",
      "Epoch 66/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 68.8421 - mse: 68.8421 - mae: 6.2080 - val_loss: 145.6959 - val_mse: 145.6959 - val_mae: 7.1576\n",
      "Epoch 67/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 66.6550 - mse: 66.6550 - mae: 6.0684 - val_loss: 145.6769 - val_mse: 145.6769 - val_mae: 7.2306\n",
      "Epoch 68/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 66.4812 - mse: 66.4812 - mae: 5.9677 - val_loss: 145.8913 - val_mse: 145.8913 - val_mae: 7.1324\n",
      "Epoch 69/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 65.8769 - mse: 65.8769 - mae: 5.9188 - val_loss: 144.5307 - val_mse: 144.5307 - val_mae: 7.2631\n",
      "Epoch 70/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 66.3151 - mse: 66.3151 - mae: 6.0146 - val_loss: 145.0665 - val_mse: 145.0665 - val_mae: 7.0394\n",
      "Epoch 71/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 65.0614 - mse: 65.0614 - mae: 5.8630 - val_loss: 143.7738 - val_mse: 143.7738 - val_mae: 7.4482\n",
      "Epoch 72/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 68.2404 - mse: 68.2404 - mae: 6.1850 - val_loss: 146.0652 - val_mse: 146.0652 - val_mae: 7.1530\n",
      "Epoch 73/75\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 66.9548 - mse: 66.9548 - mae: 5.9719 - val_loss: 142.4100 - val_mse: 142.4100 - val_mae: 7.1678\n",
      "Epoch 74/75\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 65.5326 - mse: 65.5326 - mae: 5.9223 - val_loss: 143.8892 - val_mse: 143.8892 - val_mae: 7.0672\n",
      "Epoch 75/75\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 65.3446 - mse: 65.3446 - mae: 5.9192 - val_loss: 142.0236 - val_mse: 142.0236 - val_mae: 7.0361\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=5, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "#model.summary()\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])\n",
    "hist = model.fit(X_train1, y_train1, epochs=75, batch_size=50,  verbose=1, validation_split=0.2)\n",
    "y_pred= model.predict(X_test1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVGAFs2MaGfQ"
   },
   "source": [
    "#### Para encontrar la importancia de las variables dada por la red neuronal se usó un array de zeros con un 1 en la posición donde se quería obtener el coeficiente y se predijo este array con el modelo anteriormente entrenado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uZpqsCnmYJVV",
    "outputId": "2713a62c-6282-4d3f-daf9-dbdc5906b1de",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51342887, 0.62517893, 0.93927634, 0.9477129 , 0.88648379]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RN_coef=np.zeros((1,5))\n",
    "for i in range(0,5):\n",
    "  inputs = np.zeros((1,5))\n",
    "  inputs[0][i] = 1\n",
    "  tmp_coef = model.predict(inputs)\n",
    "  RN_coef[0][i] = tmp_coef\n",
    "  #print(inputs)\n",
    "RN_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "variables = df.columns[0:-1]\n",
    "importancia = np.absolute(RN_coef[0])\n",
    "ax.barh(variables,importancia)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imagenes\\RedNeuronal.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4ujtB0PbwAf",
    "outputId": "7008e2df-c18b-495e-9244-db634e227b77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error MSE: \n",
      "53.195676395431434\n"
     ]
    }
   ],
   "source": [
    "print('Error MSE: ')\n",
    "print(mean_squared_error(y_test1, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Q_61ZCSYSlM"
   },
   "source": [
    "### Preguntas adicionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kYa_huefYYwj"
   },
   "source": [
    "### **¿Qué variables tienen el mayor impacto en el precio de la vivienda? ¿Cómo aporta cada modelo al conocimiento de este impacto?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kllu1q0YYgXr"
   },
   "source": [
    "- Para la regresión lineal clásica y elastic y los modelos de ensamble se obtuvo que la variable más importantes fue la distancia la estación de transporte masivo más cercana\n",
    "- En máquinas de soporte vectorial la variable mas importante fue X4 (cantidad de tiendas cercanas), y al contrario de los primeros modelos X3 no tuvo mucho peso\n",
    "- La red neuronal le dio mucha importancia a la ubicación (latitud y longitud) y la cantidad de tiendas cercanas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B34JdY-HdZxL"
   },
   "source": [
    "### **¿Cuál es el mejor modelo entre los usados para resolver este problema? ¿Qué criterios se pueden utilizar para responder a esta pregunta?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2H-p3HzZdxkr"
   },
   "source": [
    "#### En el ejercicio se dividió el data set en datos de entrenamiento y de testeo en un ratio de 80-20, la medida de error usada fue el MSE, según esto, los modelos que menor error tuvieron fueron los arreglos de arboles:\n",
    "* Random forest, MSE = 36.28\n",
    "* XG Boost, MSE = 39.81\n",
    "\n",
    "#### Otras medidas comunmente usadas para medir el nivel de error en modelos de regresión son RMSE y MAE, (muy parecidos al error MSE usado en la actividad), y el coeficiente de determinación (R²)\n",
    "\n",
    "#### En la regresión lineal clásica para entender mejor el impacto de las variables de ubicación en los modelos, se usaron 3 data sets, uno con todas las variables estandarizadas, otro sin las variables de latitud y longitud y otro solo con latitud y longitud. De estos modelos el mejor fue el que se entrenó con todas las variables estandarizadas \n",
    "\n",
    "#### Estandarización :\n",
    "y = (x – mean) / standard_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ex_5D716TyfB",
    "4Q_61ZCSYSlM",
    "kllu1q0YYgXr"
   ],
   "name": "Actividad3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
